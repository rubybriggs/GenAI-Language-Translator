# -*- coding: utf-8 -*-
"""Ruby Briggs - GenAI Language Translator.ipynb

Automatically generated by Colab.

"""

!pip install transformers torch gradio

from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer
import torch
import gradio as gr

# Load model and tokenizer
model_name = "facebook/m2m100_1.2B"
model = M2M100ForConditionalGeneration.from_pretrained(model_name)
tokenizer = M2M100Tokenizer.from_pretrained(model_name)

def translate(text, src_lang, tgt_lang):
    # Tokenize the input text
    inputs = tokenizer(text, return_tensors="pt", padding=True)

    # Set the source and target language
    inputs["forced_bos_token_id"] = tokenizer.get_lang_id(tgt_lang)

    # Perform the translation
    with torch.no_grad():
        translated = model.generate(**inputs)

    # Decode and return the translated text
    translation = tokenizer.decode(translated[0], skip_special_tokens=True)
    return translation

# List of available languages for translation
languages = ["en", "fr", "de", "es", "it", "pt", "ru", "zh", "ja", "hi"]

# Create Gradio interface
interface = gr.Interface(
    fn=translate,
    inputs=[
        gr.Textbox(label="Text to Translate", lines=4),
        gr.Dropdown(label="Select Source Language", choices=languages, value="en"),
        gr.Dropdown(label="Select Target Language", choices=languages, value="fr"),
    ],
    outputs=gr.Textbox(label="Translated Text"),
    title="M2M-100 Language Translator",
    description="Choose source and target languages, then enter text to get the translation.",
)

# Launch the interface
interface.launch()

